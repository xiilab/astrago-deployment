{{- if index .Values "gpu-process-exporter" "enabled" }}
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: gpu-process-metrics-collector
  namespace: {{ .Release.Namespace }}
spec:
  selector:
    matchLabels:
      app: gpu-process-metrics-collector
  template:
    metadata:
      labels:
        app: gpu-process-metrics-collector
    spec:
      nodeSelector:
        {{- toYaml .Values.nodeSelector | nindent 8 }}
      tolerations:
        {{- toYaml .Values.tolerations | nindent 6 }}
      hostPID: true
      containers:
      - name: gpu-process-collector
        securityContext:
          privileged: true
        image: "{{ .Values.offline.registry | default "nvcr.io" }}/nvidia/k8s/dcgm-exporter:3.3.9-3.6.1-ubuntu22.04"
        env:
          - name: NODE_NAME
            valueFrom:
              fieldRef:
                fieldPath: spec.nodeName
        command:
        - /bin/bash
        - -c
        - |
          # ì£¼ê¸°ì ìœ¼ë¡œ GPU í”„ë¡œì„¸ìŠ¤ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ (1ë¶„ë§ˆë‹¤)
          while true; do
            echo "$(date): Starting GPU process metrics collection..."
            
            # textfile collector ë””ë ‰í„°ë¦¬ ìƒì„±
              mkdir -p /host/var/lib/node_exporter/textfile_collector
              
              # ë©”íŠ¸ë¦­ í—¤ë” ìƒì„±
              echo "# HELP gpu_process_count Number of active GPU processes per GPU" > /tmp/gpu_processes.prom
              echo "# TYPE gpu_process_count gauge" >> /tmp/gpu_processes.prom
              echo "# HELP gpu_total_processes Total number of GPU processes across all GPUs" >> /tmp/gpu_processes.prom
              echo "# TYPE gpu_total_processes gauge" >> /tmp/gpu_processes.prom
              echo "# HELP gpu_process_utilization GPU utilization per process with detailed info" >> /tmp/gpu_processes.prom
              echo "# TYPE gpu_process_utilization gauge" >> /tmp/gpu_processes.prom
              echo "# HELP gpu_process_memory_utilization GPU memory utilization per process" >> /tmp/gpu_processes.prom
              echo "# TYPE gpu_process_memory_utilization gauge" >> /tmp/gpu_processes.prom
              echo "# HELP gpu_process_info GPU process information with Pod/Container details" >> /tmp/gpu_processes.prom
              echo "# TYPE gpu_process_info gauge" >> /tmp/gpu_processes.prom
              echo "# HELP gpu_process_start_time_seconds Process start time in seconds since epoch" >> /tmp/gpu_processes.prom
              echo "# TYPE gpu_process_start_time_seconds gauge" >> /tmp/gpu_processes.prom
              
              # GPU í”„ë¡œì„¸ìŠ¤ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ (nvidia-smi ê¸°ë°˜)
              total_processes=0
              
              echo "Collecting GPU process information from nvidia-smi..."
              echo "Checking MIG mode status..."
              
              # MIG ëª¨ë“œ í™•ì¸
              mig_enabled=$(nvidia-smi --query-gpu=mig.mode.current --format=csv,noheader,nounits 2>/dev/null | grep -v "N/A" | head -1 || echo "")
              
              if [ -n "$mig_enabled" ] && [ "$mig_enabled" = "Enabled" ]; then
                echo "MIG mode detected - using MIG-aware GPU detection"
                # MIG ì¸ìŠ¤í„´ìŠ¤ ì •ë³´ ìˆ˜ì§‘ (index, uuid, memory ë“±)
                nvidia-smi -L > /tmp/gpu_list.txt
                # MIG ì¸ìŠ¤í„´ìŠ¤ì˜ ê²½ìš° UUID ê¸°ë°˜ìœ¼ë¡œ ë§¤í•‘ í…Œì´ë¸” ìƒì„±
                nvidia-smi --query-gpu=index,uuid --format=csv,noheader | grep -E "(GPU|MIG)" | tr -d ' ' > /tmp/gpu_mapping.txt
                # MIG CI ID ì •ë³´ë„ ìˆ˜ì§‘
                nvidia-smi --query-gpu=index,uuid,mig.gpu_instance_id,mig.compute_instance_id --format=csv,noheader | grep -E "(GPU|MIG)" | tr -d ' ' > /tmp/gpu_ci_mapping.txt
              else
                echo "Standard GPU mode detected - using traditional GPU detection"
                # ê¸°ì¡´ ë°©ì‹: GPU ì¸ë±ìŠ¤ì™€ Bus ID ë§¤í•‘ í…Œì´ë¸” ìƒì„±
                nvidia-smi --query-gpu=index,pci.bus_id --format=csv,noheader,nounits | tr -d ' ' > /tmp/gpu_mapping.txt
                # ì¼ë°˜ GPUì—ì„œëŠ” CI IDê°€ ì—†ìœ¼ë¯€ë¡œ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •
                nvidia-smi --query-gpu=index,pci.bus_id --format=csv,noheader,nounits | tr -d ' ' | awk -F',' '{print $1","$2",N/A,N/A"}' > /tmp/gpu_ci_mapping.txt
              fi
              
              # ë™ì ìœ¼ë¡œ GPU/MIG ì¸ìŠ¤í„´ìŠ¤ ëª©ë¡ ìƒì„±
              gpu_list=$(nvidia-smi --query-gpu=index --format=csv,noheader,nounits)
              
              # GPUë³„ë¡œ í”„ë¡œì„¸ìŠ¤ ì¹´ìš´íŠ¸ ì´ˆê¸°í™” (ë™ì )
              echo "$gpu_list" | while read gpu_index; do
                gpu_index=$(echo "$gpu_index" | tr -d ' ')
                echo "0" > /tmp/gpu_${gpu_index}_count.tmp
              done
              
              # ëª¨ë“  GPU í”„ë¡œì„¸ìŠ¤ ì •ë³´ë¥¼ í•œë²ˆì— ì¡°íšŒ
              if [ -n "$mig_enabled" ] && [ "$mig_enabled" = "Enabled" ]; then
                # MIG í™˜ê²½ì—ì„œëŠ” UUID ê¸°ë°˜ìœ¼ë¡œ í”„ë¡œì„¸ìŠ¤ ë§¤í•‘ (CI ID í¬í•¨)
                all_gpu_processes=$(nvidia-smi --query-compute-apps=gpu_uuid,pid,process_name,used_gpu_memory --format=csv,noheader,nounits 2>/dev/null | grep -v "No running processes found" || true)
              else
                # ê¸°ì¡´ ë°©ì‹: Bus ID ê¸°ë°˜
                all_gpu_processes=$(nvidia-smi --query-compute-apps=gpu_bus_id,pid,process_name,used_gpu_memory --format=csv,noheader,nounits 2>/dev/null | grep -v "No running processes found" || true)
              fi
              
              # ëª¨ë“  í”„ë¡œì„¸ìŠ¤ë¥¼ ì²˜ë¦¬í•˜ì—¬ ì •í™•í•œ GPU ë§¤ì¹­
              if [ -n "$all_gpu_processes" ]; then
                echo "$all_gpu_processes" | while IFS=',' read -r gpu_identifier actual_pid process_name gpu_memory; do
                  # ê³µë°± ì œê±°
                  actual_pid=$(echo "$actual_pid" | tr -d ' ')
                  process_name=$(echo "$process_name" | tr -d ' ')
                  gpu_memory=$(echo "$gpu_memory" | tr -d ' ')
                  gpu_identifier=$(echo "$gpu_identifier" | tr -d ' ')
                  
                  # í”„ë¡œì„¸ìŠ¤ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸
                  if [ -n "$actual_pid" ] && [ "$actual_pid" != "-" ] && [ "$actual_pid" != "N/A" ]; then
                    
                    # GPU ì‹ë³„ìì—ì„œ GPU ì¸ë±ìŠ¤ ì°¾ê¸°
                    if [ -n "$mig_enabled" ] && [ "$mig_enabled" = "Enabled" ]; then
                      # MIG í™˜ê²½: UUID ê¸°ë°˜ ë§¤í•‘
                      gpu_id=$(awk -F',' -v id="$gpu_identifier" '$2==id {print $1}' /tmp/gpu_mapping.txt)
                      # CI ID ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                      ci_info=$(awk -F',' -v id="$gpu_identifier" '$2==id {print $3","$4}' /tmp/gpu_ci_mapping.txt)
                      gi_id=$(echo "$ci_info" | cut -d',' -f1)
                      ci_id=$(echo "$ci_info" | cut -d',' -f2)
                      
                      # CI IDê°€ ì—†ê±°ë‚˜ N/Aì¸ ê²½ìš° ê¸°ë³¸ê°’ ì„¤ì •
                      if [ -z "$gi_id" ] || [ "$gi_id" = "N/A" ]; then
                        gi_id="none"
                      fi
                      if [ -z "$ci_id" ] || [ "$ci_id" = "N/A" ]; then
                        ci_id="none"
                      fi
                    else
                      # ê¸°ì¡´ í™˜ê²½: Bus ID ê¸°ë°˜ ë§¤í•‘
                      gpu_id=$(awk -F',' -v id="$gpu_identifier" '$2==id {print $1}' /tmp/gpu_mapping.txt)
                                              # ì¼ë°˜ GPUì—ì„œëŠ” CI ID ì—†ìŒ
                        gi_id="none"
                        ci_id="none"
                    fi
                    
                    if [ -z "$gpu_id" ]; then
                      echo "Warning: Could not find GPU index for identifier: $gpu_identifier"
                      gpu_id="0"  # ê¸°ë³¸ê°’
                    fi
                    
                    echo "Process PID $actual_pid detected on GPU $gpu_id (Identifier: $gpu_identifier)"
                    
                    # GPU ì‚¬ìš©ë¥  ë° ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì€ ê¸°ë³¸ê°’ ì„¤ì •
                    gpu_util="0"  # ê¸°ë³¸ê°’
                    mem_util="0"  # ê¸°ë³¸ê°’
                    
                    # ë…¸ë“œ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
                    node_name=$NODE_NAME
                    
                    # í”„ë¡œì„¸ìŠ¤ë³„ GPU ì‚¬ìš©ë¥  ì •ë³´ ìˆ˜ì§‘ (nvidia-smi pmon ì‚¬ìš©)
                    if [ -n "$mig_enabled" ] && [ "$mig_enabled" = "Enabled" ]; then
                      # MIG í™˜ê²½ì—ì„œëŠ” UUID ê¸°ë°˜ìœ¼ë¡œ í”„ë¡œì„¸ìŠ¤ ë§¤í•‘
                      gpu_index=$(echo "$gpu_id" | cut -d'-' -f1)
                    else
                      # ê¸°ì¡´ í™˜ê²½: Bus ID ê¸°ë°˜
                      gpu_index=$(echo "$gpu_id" | cut -d':' -f1)
                    fi
                    
                    # nvidia-smi pmonìœ¼ë¡œ í”„ë¡œì„¸ìŠ¤ ì •ë³´ ìˆ˜ì§‘
                    echo "â–¶ï¸ Running nvidia-smi pmon for GPU index: $gpu_index, PID: $actual_pid"
                    
                    process_stats=$(nvidia-smi pmon -i "$gpu_index" -s um -c 1 2>/dev/null | tail -n +3 | grep "$actual_pid" || echo "")
                    
                    echo "ğŸ“‹ Raw process_stats:"
                    echo "$process_stats"
                    
                    if [ -n "$process_stats" ]; then
                      # GPU ì‚¬ìš©ë¥ ê³¼ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì¶œ
                      gpu_util=$(echo "$process_stats" | awk '{print $4}')
                      used_mem=$(echo "$process_stats" | awk '{print $10}')
                      
                      echo "âœ… Parsed values:"
                      echo "GPU Utilization : $gpu_util"
                      echo "Used GPU Memory : $used_mem MiB"
                      
                      # ì „ì²´ GPU ë©”ëª¨ë¦¬ ê°€ì ¸ì˜¤ê¸°
                      total_mem=$(nvidia-smi --query-gpu=memory.total --format=csv,noheader,nounits -i "$gpu_index")
                      echo "Total GPU Memory: $total_mem MiB"
                      
                      # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ê³„ì‚° (ì†Œìˆ˜ì  í•œ ìë¦¬)
                      if [[ $total_mem =~ ^[0-9]+$ && $used_mem =~ ^[0-9]+$ ]]; then
                        mem_util=$(awk -v u="$used_mem" -v t="$total_mem" 'BEGIN{printf "%.1f", (u/t)*100}')
                        echo "ğŸ§® Memory Utilization: $mem_util %"
                      else
                        echo "âš ï¸ Memory values are not numeric: used_mem='$used_mem', total_mem='$total_mem'"
                      fi
                    else
                      echo "ğŸš« No matching process found in nvidia-smi pmon for PID $actual_pid on GPU $gpu_index"
                    fi
                    
                    # Pod/Container ì •ë³´ë¥¼ /procì—ì„œ ì¡°íšŒ
                    pod_name="unknown"
                    container_name="unknown"
                    namespace="unknown"
                    process_start_time="0"
                    
                    # í”„ë¡œì„¸ìŠ¤ ì‹œì‘ ì‹œê°„ ì¡°íšŒ
                    if [ -f "/host/proc/$actual_pid/stat" ]; then
                      # /proc/[pid]/statì˜ 22ë²ˆì§¸ í•„ë“œê°€ í”„ë¡œì„¸ìŠ¤ ì‹œì‘ ì‹œê°„ (jiffies)
                      start_time_jiffies=$(cat /host/proc/$actual_pid/stat 2>/dev/null | awk '{print $22}' || echo "0")
                      if [ "$start_time_jiffies" != "0" ]; then
                        # ì‹œìŠ¤í…œ ë¶€íŒ… ì‹œê°„ ê³„ì‚°
                        if [ -f "/host/proc/uptime" ]; then
                          uptime_seconds=$(awk '{print int($1)}' /host/proc/uptime)
                          current_time=$(date +%s)
                          boot_time=$((current_time - uptime_seconds))
                          # jiffiesë¥¼ ì´ˆë¡œ ë³€í™˜í•˜ê³  ë¶€íŒ… ì‹œê°„ì„ ë”í•´ ì‹¤ì œ ì‹œì‘ ì‹œê°„ ê³„ì‚°
                          process_start_time=$((boot_time + (start_time_jiffies / 100)))
                        fi
                      fi
                    fi
                    
                    # cgroupì—ì„œ Pod ì •ë³´ ì¶”ì¶œ ì‹œë„
                    if [ -f "/host/proc/$actual_pid/cgroup" ]; then
                      cgroup_info=$(cat /host/proc/$actual_pid/cgroup 2>/dev/null || echo "")
                      if echo "$cgroup_info" | grep -q "kubepods"; then
                        # Kubernetes Podì¸ ê²½ìš° Pod UID ì¶”ì¶œ
                        pod_uid=$(echo "$cgroup_info" | grep -o 'pod[a-f0-9-]*' | head -1 | sed 's/pod//' || echo "unknown")
                        if [ "$pod_uid" != "unknown" ]; then
                          pod_name="pod-$pod_uid"
                          namespace="detected"
                        fi
                      fi
                    fi
                    
                    # MIG í™˜ê²½ì—ì„œëŠ” gpu_idì— MIG ì •ë³´ í¬í•¨ ê°€ëŠ¥ (ì˜ˆ: "0/0/0")
                    gpu_display=$(echo "$gpu_id" | sed 's/\//_/g')  # ìŠ¬ë˜ì‹œë¥¼ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ë³€ê²½
                    
                    # í•´ë‹¹ GPUì—ë§Œ ë©”íŠ¸ë¦­ ìƒì„± (CI ID ë¼ë²¨ ì¶”ê°€)
                    echo "gpu_process_utilization{node=\"$node_name\",gpu=\"$gpu_display\",pid=\"$actual_pid\",command=\"$process_name\",pod=\"$pod_name\",namespace=\"$namespace\",container=\"$container_name\",gpu_memory=\"${gpu_memory}MiB\",start_time=\"$process_start_time\",gi_id=\"$gi_id\",ci_id=\"$ci_id\"} $gpu_util" >> /tmp/gpu_processes.prom
                    echo "gpu_process_memory_utilization{node=\"$node_name\",gpu=\"$gpu_display\",pid=\"$actual_pid\",command=\"$process_name\",pod=\"$pod_name\",namespace=\"$namespace\",container=\"$container_name\",gpu_memory=\"${gpu_memory}MiB\",start_time=\"$process_start_time\",gi_id=\"$gi_id\",ci_id=\"$ci_id\"} $mem_util" >> /tmp/gpu_processes.prom
                    echo "gpu_process_info{node=\"$node_name\",gpu=\"$gpu_display\",pid=\"$actual_pid\",command=\"$process_name\",pod=\"$pod_name\",namespace=\"$namespace\",container=\"$container_name\",status=\"active\",gpu_memory=\"${gpu_memory}MiB\",start_time=\"$process_start_time\",gi_id=\"$gi_id\",ci_id=\"$ci_id\"} 1" >> /tmp/gpu_processes.prom
                    
                    # í•´ë‹¹ GPUì˜ í”„ë¡œì„¸ìŠ¤ ì¹´ìš´íŠ¸ ì¦ê°€
                    current_count=$(cat /tmp/gpu_${gpu_id}_count.tmp 2>/dev/null || echo "0")
                    echo $((current_count + 1)) > /tmp/gpu_${gpu_id}_count.tmp
                    total_processes=$((total_processes + 1))
                  fi
                done
              fi
              
              # ê° GPUë³„ í”„ë¡œì„¸ìŠ¤ ì¹´ìš´íŠ¸ ë° idle ìƒíƒœ ì²˜ë¦¬ (ë™ì )
              echo "$gpu_list" | while read gpu_index; do
                gpu_index=$(echo "$gpu_index" | tr -d ' ')
                gpu_display=$(echo "$gpu_index" | sed 's/\//_/g')  # ìŠ¬ë˜ì‹œë¥¼ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ë³€ê²½
                process_count=$(cat /tmp/gpu_${gpu_index}_count.tmp 2>/dev/null || echo "0")
                
                # CI ID ì •ë³´ ê°€ì ¸ì˜¤ê¸° (idle ìƒíƒœìš©)
                if [ -n "$mig_enabled" ] && [ "$mig_enabled" = "Enabled" ]; then
                  ci_info=$(awk -F',' -v idx="$gpu_index" '$1==idx {print $3","$4}' /tmp/gpu_ci_mapping.txt)
                  gi_id=$(echo "$ci_info" | cut -d',' -f1)
                  ci_id=$(echo "$ci_info" | cut -d',' -f2)
                  if [ -z "$gi_id" ] || [ "$gi_id" = "N/A" ]; then
                    gi_id="none"
                  fi
                  if [ -z "$ci_id" ] || [ "$ci_id" = "N/A" ]; then
                    ci_id="none"
                  fi
                else
                  gi_id="none"
                  ci_id="none"
                fi
                
                echo "gpu_process_count{gpu=\"$gpu_display\",gi_id=\"$gi_id\",ci_id=\"$ci_id\"} $process_count" >> /tmp/gpu_processes.prom
                
                # í”„ë¡œì„¸ìŠ¤ê°€ ì—†ëŠ” GPUëŠ” idle ìƒíƒœë¡œ í‘œì‹œ (CI ID í¬í•¨)
                if [ "$process_count" -eq 0 ]; then
                  echo "gpu_process_info{node=\"$node_name\",gpu=\"$gpu_display\",pid=\"none\",command=\"none\",pod=\"none\",namespace=\"none\",container=\"none\",status=\"idle\",gpu_memory=\"0MiB\",gi_id=\"$gi_id\",ci_id=\"$ci_id\"} 0" >> /tmp/gpu_processes.prom
                fi
              done
              
              echo "gpu_total_processes $total_processes" >> /tmp/gpu_processes.prom
              
              # íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€
              echo "# Generated at $(date)" >> /tmp/gpu_processes.prom
              
              # ì„ì‹œ íŒŒì¼ ì •ë¦¬
              rm -f /tmp/gpu_mapping.txt /tmp/gpu_ci_mapping.txt /tmp/gpu_*_count.tmp /tmp/gpu_list.txt
              
              # ë©”íŠ¸ë¦­ íŒŒì¼ ì´ë™
              mv /tmp/gpu_processes.prom /host/var/lib/node_exporter/textfile_collector/gpu_processes.prom
              
              echo "$(date): GPU process metrics collected with MIG-aware GPU mapping"
              cat /host/var/lib/node_exporter/textfile_collector/gpu_processes.prom
            
            # 60ì´ˆ ëŒ€ê¸° (1ë¶„ë§ˆë‹¤ ì‹¤í–‰)
            sleep 60
          done
        resources:
          {{- toYaml .Values.collection.resources | nindent 10 }}
        volumeMounts:
        - name: host-var
          mountPath: /host/var
        - name: host-proc
          mountPath: /host/proc
          readOnly: true
      volumes:
      - name: host-var
        hostPath:
          path: /var
      - name: host-proc
        hostPath:
          path: /proc
{{- end }}
