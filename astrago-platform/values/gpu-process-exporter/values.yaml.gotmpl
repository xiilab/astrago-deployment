# GPU Process Exporter Configuration
# Exports GPU process metrics to Prometheus via HTTP API + ServiceMonitor

gpu-process-exporter:
  enabled: {{ index .Values "gpu-process-exporter" "enabled" | default "true" }}

# HTTP Server settings
httpServer:
  # Port for metrics endpoint
  port: 8080
  # Metrics collection interval (seconds)
  interval: 30
  
  # Resource limits
  resources:
    limits:
      cpu: 100m
      memory: 128Mi
    requests:
      cpu: 50m
      memory: 64Mi

# Service configuration
service:
  enabled: true
  type: ClusterIP
  port: 8080
  targetPort: 8080
  labels: {}
  annotations: {}

# ServiceMonitor configuration for Prometheus Operator
serviceMonitor:
  enabled: true
  interval: 30s
  scrapeTimeout: 10s
  labels: {}
  # Selector labels for the service
  selector:
    matchLabels:
      app: gpu-process-exporter

# Security context for GPU access
securityContext:
  privileged: true

# Host access for GPU monitoring
hostAccess:
  # Use host PID namespace to see all processes
  hostPID: true

# Note: GPU devices are automatically detected via nvidia-smi
# No manual configuration needed for GPU count or device indices

# Node selection
nodeSelector:
  nvidia.com/gpu.present: "true"

# Tolerations for GPU nodes
tolerations:
- key: nvidia.com/gpu
  operator: Exists
  effect: NoSchedule
